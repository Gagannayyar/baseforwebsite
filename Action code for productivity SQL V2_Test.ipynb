{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The process has started at 2021-01-04 14:23:03.199490\n",
      "Please input month: December\n",
      "Please enter the week in mm_dd_yyyy format only or write EOM: 12_05_2020\n",
      "Please enter the path to save the file: sdc\n",
      "Completed for BH_AL\n",
      "Completed for Barnabas\n",
      "Completed for BENE_ID\n",
      "Completed for CH_CA\n",
      "Completed for CHLD_FL\n",
      "Completed for Crozer\n",
      "Completed for EMCO_GA\n",
      "Completed for ECHA_AL\n",
      "Completed for HUMB_NV\n",
      "Completed for HSGN_LA\n",
      "Completed for JPH_LA\n",
      "Completed for LAKE_OH\n",
      "Completed for LNOL_MN\n",
      "Completed for LIFE_TN\n",
      "Completed for SIMP_MS\n",
      "Completed for South_Florida\n",
      "Completed for TORR_CA\n",
      "Completed for UBMC_UT\n",
      "Completed for UNGH_GA\n",
      "Completed for WCDH_CO\n",
      "System generated rows removed\n",
      "UID created\n",
      "Removed duplicates\n",
      "Columns Updated\n",
      "Action code uploaded to dataframe in python\n",
      "Action code uploaded to SQL Server\n",
      "The total time taken for the entire process was 60 minutes\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This scripts is for removing the action code duplicates and system generated users by creating an \n",
    "UID using Activity date, encounter number, claim number and Rep name\n",
    "\"\"\"\n",
    "\n",
    "#Importing nessary libraries\n",
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import calendar\n",
    "from calendar import monthrange\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "from importlib import reload\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "reload(sys)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "print(\"The process has started at {}\".format(datetime.datetime.now()))\n",
    "\n",
    "#This is the main folderpath\n",
    "folder = r'\\\\filesrvwhq\\PowerWorks_Ops\\Ambulatory Services\\Client and Team Folders\\0_New_Client_Folders'\n",
    "\n",
    "#getting the right month folder\n",
    "month_input = input(\"Please input month: \")\n",
    "month_namefin = month_input.title()\n",
    "month_name = month_input[0:3]\n",
    "datetime_object = datetime.datetime.strptime(month_name, \"%b\")\n",
    "month_number = datetime_object.month\n",
    "folder_month = str(month_number)+'_'+str(month_namefin)\n",
    "current_year = str(2020)\n",
    "week_name = input(\"Please enter the week in mm_dd_yyyy format only or write EOM: \")\n",
    "current_time = str(datetime.datetime.now())\n",
    "#Getting the list of client folders\\\n",
    "list_of_c = [\n",
    " 'Baptist_Health_BH_AL',\n",
    " 'Barnabas_BARN_HS',\n",
    " 'Benewah_BENE_ID',\n",
    " 'Chinese_Hospital_CH_CA',\n",
    " 'Nicklaus_Childrens_CHLD_FL',\n",
    " 'Crozer_PHAN_PA',\n",
    " 'Emory_Healthcare_EMCO_GA',\n",
    " 'Escambia_ECHA_AL',\n",
    " 'Humboldt_HUMB_NV',\n",
    " 'Internal_Medicine_HSGN_LA',\n",
    " 'Jackson_Parish_JPH_LA',\n",
    " 'Lake_Health_LAKE_OH',\n",
    " 'Land_O_Lakes_LNOL_MN',\n",
    " 'Lawrence_LMH_KS',\n",
    " 'Lawrence_LMH_KS_New_Domain',\n",
    " 'Lexington_TCAH_NE',\n",
    " 'LifePoint_LIFE_TN',\n",
    " 'Maniilaq_MANQ_AK',\n",
    " 'Simpson_General_SIMP_MS',\n",
    " 'South_Florida_68906',\n",
    " 'Torrance_TORR_CA',\n",
    " 'Uintah_Basin_UBMC_UT',\n",
    " 'Union_General_UNGH_GA',\n",
    " 'Wray_Community_WCDH_CO']\n",
    "\n",
    "\n",
    "list_of_folder = ['Baptist_Health_BH_AL',\n",
    " 'Barnabas_BARN_HS',\n",
    " 'Benewah_BENE_ID',\n",
    " 'Chinese_Hospital_CH_CA',\n",
    " 'Nicklaus_Childrens_CHLD_FL',\n",
    " 'Crozer_PHAN_PA',\n",
    " 'Emory_Healthcare_EMCO_GA',\n",
    " 'Escambia_ECHA_AL',\n",
    " 'Humboldt_HUMB_NV',\n",
    " 'Internal_Medicine_HSGN_LA',\n",
    " 'Jackson_Parish_JPH_LA',\n",
    " 'Lake_Health_LAKE_OH',\n",
    " 'Land_O_Lakes_LNOL_MN',\n",
    " 'LifePoint_LIFE_TN',\n",
    " 'Simpson_General_SIMP_MS',\n",
    " 'South_Florida_68906',\n",
    " 'Torrance_TORR_CA',\n",
    " 'Uintah_Basin_UBMC_UT',\n",
    " 'Union_General_UNGH_GA',\n",
    " 'Wray_Community_WCDH_CO']\n",
    "\n",
    "#Asking for local_path to save file\n",
    "local_path = input(\"Please enter the path to save the file: \")\n",
    "\n",
    "\n",
    "#Creating folder with path list\n",
    "folderin_list = []\n",
    "for i in list_of_folder:\n",
    "    folderin = os.path.join(folder,i)\n",
    "    folderin_foo = folderin + \"\\\\\" + current_year + \"\\\\\" + folder_month + \"\\\\\" + week_name\n",
    "    folderin_list.append(folderin_foo)\n",
    "      \n",
    "#getting the EATB\n",
    "\n",
    "if week_name ==\"EOM\":\n",
    "    file_name = \"Action Codes EOM\"\n",
    "else:\n",
    "    file_name = \"Action Codes Weekly\"\n",
    "\n",
    "#Getting the list of interest and removing pseudo filesl\n",
    "interest_list = []\n",
    "for i in folderin_list:\n",
    "    list_of_files = os.listdir(path=i)\n",
    "    for j in list_of_files:\n",
    "        if file_name in j:\n",
    "            interest_list.append(i+'\\\\'+j)\n",
    "            for m in interest_list:\n",
    "                size = os.path.getsize(m)\n",
    "                if size < 2000:\n",
    "                    interest_list.remove(m)\n",
    "                \n",
    "\n",
    "#Copying the files\n",
    "num = 0\n",
    "all_data = pd.DataFrame()\n",
    "for i in interest_list:\n",
    "    df = pd.read_excel(i, sheet_name = \"Action Code\")\n",
    "    df['Client'] = (i.split(\"- \")[2]).split(\".\")[0]\n",
    "   \n",
    "    all_data = all_data.append(df,ignore_index=True)\n",
    "    print(f\"Completed for {df['Client'][1]}\")\n",
    "    \n",
    "total_time = time.time()\n",
    "\n",
    "\n",
    "#Removing unnessary users\n",
    "remove_users = ['Contributor_system , PARO',\n",
    "'Contributor_system , PFS_COLLE', \n",
    " 'DO NOT MODIFY , THIS ACCOUNT',\n",
    " 'DomainUser , Generated',\n",
    "'Domainuser , Generated',\n",
    " 'System , System',\n",
    "'SYSTEM , SYSTEM']\n",
    "name = \" \"\n",
    "name_list = []\n",
    "for i in all_data['Representative Name']:\n",
    "    if i not in remove_users:\n",
    "        name = i\n",
    "        name_list.append(i)\n",
    "\n",
    "all_data_filter = all_data[all_data['Representative Name'].isin(name_list)]\n",
    "print(\"System generated rows removed\")\n",
    "\n",
    "#Changing the format of activity date and created date to MM-DD-YYYY\n",
    "import datetime as dt\n",
    "all_data_filter['Activity Date'] = pd.to_datetime(all_data_filter['Activity Date'].dt.strftime(\"%m-%d-%y\"))\n",
    "all_data_filter['Activity Date'] = all_data_filter['Activity Date'].apply(lambda x: x.date())\n",
    "all_data_filter['Created Date'] = pd.to_datetime(all_data_filter['Created Date'].dt.strftime(\"%m-%d-%y\"))\n",
    "all_data_filter['Created Date'] = all_data_filter['Created Date'].apply(lambda x: x.date())\n",
    "\n",
    "\n",
    "#Creating UID with Activity Date, Encounter Number, Claim Number and Rep name\n",
    "all_data_filter['UID'] = None\n",
    "for i in range(0,len(all_data_filter['Activity Date'])):\n",
    "    all_data_filter['UID'].iloc[i] = str(all_data_filter['Activity Date'].iloc[i])+str(all_data_filter['Encounter Number'].iloc[i])+str(all_data_filter['Claim Number'].iloc[i])+str(all_data_filter['Representative Name'].iloc[i])\n",
    "print(\"UID created\")\n",
    "\n",
    "all_data_fil = all_data_filter.copy()\n",
    "\n",
    "#Creating Data frames with CLaim number \n",
    "all_data_nan = all_data_fil[all_data_fil['Claim Number'].isnull() == True] # Where claim number is null\n",
    "all_data_main = all_data_fil[all_data_fil['Claim Number'].isnull() == False]#where cliam number is not null\n",
    "all_data_nan.reset_index(inplace= True, drop=True)\n",
    "all_data_main.reset_index(inplace= True, drop=True)\n",
    "\n",
    "#Droping Dupliacte UIDs\n",
    "all_data_main.drop_duplicates(subset =\"UID\", \n",
    "                     keep = \"first\", inplace = True) \n",
    "\n",
    "#Merging both null and withoutnull data frames in one final dataframe\n",
    "all_data_semi= all_data_main.append(all_data_nan, ignore_index=True)\n",
    "all_data_semi.reset_index(inplace= True, drop=True)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Removed duplicates\")\n",
    "\n",
    "#Renaming the columns\n",
    "\n",
    "all_data_semi = all_data_semi.rename(columns={'Encounter Number':'FIN', \n",
    "                                           'Organization': 'Organization Name',\n",
    "                                            'Supervising Provider': 'Supervisor Name',\n",
    "                                            'Transmission Date':'Last Claim Date'})\n",
    "\n",
    "#Removing Columns\n",
    "\n",
    "all_data_semi = all_data_semi.drop(['Claim Number', 'Generation Date', 'Submission Date', 'UID'], axis=1)\n",
    "\n",
    "#Converting currency to number\n",
    "\n",
    "all_data_semi['Claim Amount'] =  all_data_semi['Claim Amount'].str.replace(\"$\",\"\")\n",
    "all_data_semi['Encounter Balance'] =  all_data_semi['Encounter Balance'].str.replace(\"$\",\"\")\n",
    "all_data_semi['Claim Amount'] =  all_data_semi['Claim Amount'].str.replace(\",\",\"\")\n",
    "all_data_semi['Encounter Balance'] =  all_data_semi['Encounter Balance'].str.replace(\",\",\"\")\n",
    "all_data_semi['Claim Amount'] =  all_data_semi['Claim Amount'].str.replace(\"(\",\"\")\n",
    "all_data_semi['Encounter Balance'] = all_data_semi['Encounter Balance'].str.replace(\"(\",\"\")\n",
    "all_data_semi['Claim Amount'] =  all_data_semi['Claim Amount'].str.replace(\")\",\"\")\n",
    "all_data_semi['Encounter Balance'] =  all_data_semi['Encounter Balance'].str.replace(\")\",\"\")\n",
    "all_data_semi['Claim Amount'].astype('float')\n",
    "all_data_semi['Encounter Balance'].astype('float')\n",
    "\n",
    "new_col_list = ['Activity Date', 'Billing Entity', 'FIN',\n",
    "       'Health Plan', 'Discharge Date', 'Discharge Aging Range',\n",
    "       'Last Claim Date', 'Claim Amount', 'Encounter Balance',\n",
    "       'Supervisor Name', 'Representative Name', 'Action Code', 'Action Level',\n",
    "       'Action Code Description',\n",
    "       'Comment', 'Created Date','Client']\n",
    "\n",
    "all_data_semi = all_data_semi[new_col_list]\n",
    "print(\"Columns Updated\")\n",
    "\n",
    "all_data_semi.reset_index(drop=True)\n",
    "all_data_fil = all_data_semi.to_numpy()\n",
    "\n",
    "\n",
    "print(\"Action code uploaded to dataframe in python\")\n",
    "\n",
    "\"\"\" \n",
    "Starting the SQL update using pyodbc library. The values in the tables are \n",
    "converted to numpy arrays so that the same can be appended using for loop into desired SQL Server\n",
    "\"\"\"\n",
    "\n",
    "#Converting the NaT pandas values to None type\n",
    "def remove_NaT():\n",
    "    for i in all_data_fil:\n",
    "        for n,j in enumerate(i):\n",
    "            if j is pd.NaT:\n",
    "                i[n] = None\n",
    "                \n",
    "                \n",
    "    return all_data_fil\n",
    "\n",
    "\n",
    "\n",
    "#Connecting to SQL Server\n",
    "server_name = \"W1751904\\LOCAL_CERNER\"\n",
    "database_name = \"Test_Productivity_Dashboard\"\n",
    "conn = pyodbc.connect(Driver='{SQL Server Native Client 11.0}',\n",
    "                      Server=server_name,\n",
    "                      Database=database_name,\n",
    "                      trusted_connection='yes')\n",
    "\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "#Uploading in SQL Action Code table\n",
    "insert_query = \"\"\"INSERT INTO Action_Code ([Activity Date], [Billing Entity], [FIN],[Claim Number],\n",
    "                                       [Health Plan], [Discharge Date], [Discharge Aging Range],\n",
    "                                       [Last Claim Date], [Claim Amount], [Encounter Balance],\n",
    "                                       [Supervisor Name], [Representative Name], [Action Code],\n",
    "                                       [Action Level],[Action Code Description],[Comment],\n",
    "                                       [Created Date],[Client]) VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\n",
    "                    \"\"\"\n",
    "\n",
    "\n",
    "for row in all_data_fil:\n",
    "    values = (row[0],str(row[1]),str(row[2]),str(row[3]),row[4],str(row[5]),row[6],str(row[7]),row[8],str(row[9]),str(row[10]),str(row[11]),str(row[12]),str(row[13]),str(row[14]),row[15],str(row[16]))\n",
    "    cursor.execute(insert_query,values)\n",
    "\n",
    "conn.commit()\n",
    "print(\"Action code uploaded to SQL Server\")\n",
    "\n",
    "#all_data_fil.to_excel(local_path+\"\\\\\"+list_of_folder[0]+\".xlsx\", index=False)\n",
    "#print(f\"File saved to {local_path}\")\n",
    "\n",
    "total_time = time.time()\n",
    "print(f\"The total time taken for the entire process was {round((total_time - start)/60)} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_c = [\n",
    " 'Barnabas_BARN_HS',\n",
    " 'Benewah_BENE_ID',\n",
    " 'Chinese_Hospital_CH_CA',\n",
    " 'Crozer_PHAN_PA',\n",
    " 'Emory_Healthcare_EMCO_GA',\n",
    " 'Escambia_ECHA_AL',\n",
    " 'Humboldt_HUMB_NV',\n",
    " 'Internal_Medicine_HSGN_LA',\n",
    " 'Jackson_Parish_JPH_LA',\n",
    " 'Lake_Health_LAKE_OH',\n",
    " 'Land_O_Lakes_LNOL_MN',\n",
    " 'Lawrence_LMH_KS',\n",
    " 'Lawrence_LMH_KS_New_Domain',\n",
    " 'Lexington_TCAH_NE',\n",
    " 'LifePoint_LIFE_TN',\n",
    " 'Maniilaq_MANQ_AK',\n",
    " 'Simpson_General_SIMP_MS',\n",
    " 'South_Florida_68906',\n",
    " 'Torrance_TORR_CA',\n",
    " 'Uintah_Basin_UBMC_UT',\n",
    " 'Union_General_UNGH_GA',\n",
    " 'Wray_Community_WCDH_CO']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BH_AL.xlsx'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interest_list[0].split(\"- \")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now.month+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_main.sort_values('UID', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_data_main.drop_duplicates(subset =\"UID\", \n",
    "                     keep = \"first\", inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_data_fil= all_data_main.append(all_data_nan, ignore_index=True)\n",
    "all_data_fil.reset_index(inplace= True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fil.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fil.to_excel(r\"C:\\Users\\GN082282\\OneDrive - Cerner Corporation\\Documents\\all_data_fil.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(interest_list[0].split(\"-\")[2]).split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
